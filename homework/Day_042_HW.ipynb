{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "目前你應該已經要很清楚資料集中，資料的型態是什麼樣子囉！包含特徵 (features) 與標籤 (labels)。因此要記得未來不管什麼專案，必須要把資料清理成相同的格式，才能送進模型訓練。\n",
    "今天的作業開始踏入決策樹這個非常重要的模型，請務必確保你理解模型中每個超參數的意思，並試著調整看看，對最終預測結果的影響為何"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 試著調整 DecisionTreeClassifier(...) 中的參數，並觀察是否會改變結果？\n",
    "2. 改用其他資料集 (boston, wine)，並與回歸模型的結果進行比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.9333333333333333\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Feature importance:  [0.06852248 0.01846895 0.48113985 0.43186872]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, metrics\n",
    "\n",
    "# 如果是分類問題，請使用 DecisionTreeClassifier，若為回歸問題，請使用 DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 讀取鳶尾花資料集\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.5, random_state=9)\n",
    "\n",
    "# 建立模型\n",
    "#clf = DecisionTreeClassifier()\n",
    "clf = DecisionTreeClassifier(criterion = 'gini', max_depth = None, min_samples_split = 2, min_samples_leaf = 1)\n",
    "\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)\n",
    "\n",
    "print(iris.feature_names)\n",
    "\n",
    "print(\"Feature importance: \", clf.feature_importances_)\n",
    "\n",
    "print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.96\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Feature importance:  [0.06148341 0.02068906 0.56296204 0.35486549]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "clf2 = DecisionTreeClassifier(criterion = 'entropy', max_depth = None, min_samples_split = 2, min_samples_leaf = 1)\n",
    "\n",
    "# 訓練模型\n",
    "clf2.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred2 = clf2.predict(x_test)\n",
    "\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred2)\n",
    "print(\"Acuuracy: \", acc)\n",
    "\n",
    "print(iris.feature_names)\n",
    "\n",
    "print(\"Feature importance: \", clf2.feature_importances_)\n",
    "\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由clf與clf2來看，改變DecisionTreeClassifier 中的參數會影響其結果\n",
    "1. criterion 為'gini'及'entropy' 兩個時，當min_samples_split = 2，'entropy'的準確度較高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.7114467408585056\n",
      "Feature importance:  [0.         0.         0.         0.00910048 0.0061658  0.00109992\n",
      " 0.00316764 0.         0.         0.         0.00058197 0.00722871\n",
      " 0.01149364 0.01404181 0.00755183 0.         0.         0.00021054\n",
      " 0.0356831  0.002711   0.         0.15093984 0.00754992 0.\n",
      " 0.         0.         0.01386582 0.02763872 0.14347015 0.06753077\n",
      " 0.         0.         0.         0.04092218 0.03255451 0.02240725\n",
      " 0.01293796 0.00121197 0.00895178 0.         0.00328095 0.00177097\n",
      " 0.01402228 0.01294921 0.00635372 0.01612328 0.00533561 0.\n",
      " 0.         0.00175525 0.01110047 0.03792214 0.13310339 0.00130492\n",
      " 0.00966715 0.         0.         0.00287453 0.00517496 0.00080533\n",
      " 0.0092281  0.06408478 0.03392205 0.00020358]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.7, random_state=1)\n",
    "\n",
    "clf3 = DecisionTreeRegressor()\n",
    "\n",
    "# 訓練模型\n",
    "clf3.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred3 = clf3.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred3)\n",
    "print(\"Acuuracy: \", acc)\n",
    "\n",
    "print(\"Feature importance: \", clf3.feature_importances_)\n",
    "\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.8186874304783093\n",
      "Feature importance:  [0.         0.         0.02138402 0.00712848 0.0025146  0.04232483\n",
      " 0.         0.         0.         0.00340454 0.01390322 0.\n",
      " 0.01967592 0.02083878 0.         0.         0.         0.00201223\n",
      " 0.0149501  0.0737031  0.00067074 0.10356875 0.         0.\n",
      " 0.         0.00645412 0.04680987 0.         0.00894743 0.\n",
      " 0.14684179 0.         0.         0.04817427 0.01194757 0.00205081\n",
      " 0.0772329  0.01600547 0.01467933 0.         0.         0.\n",
      " 0.08674493 0.05642322 0.00626016 0.0256117  0.         0.\n",
      " 0.         0.00067074 0.00186862 0.00934207 0.         0.03206923\n",
      " 0.00121057 0.00157288 0.         0.         0.01776375 0.00162815\n",
      " 0.00231292 0.04130656 0.00533757 0.00465406]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "clf2 = DecisionTreeClassifier(criterion = 'entropy', max_depth = None, min_samples_split = 2, min_samples_leaf = 1)\n",
    "\n",
    "# 訓練模型\n",
    "clf2.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred2 = clf2.predict(x_test)\n",
    "\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred2)\n",
    "print(\"Acuuracy: \", acc)\n",
    "\n",
    "print(\"Feature importance: \", clf2.feature_importances_)\n",
    "\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
